---
title: "SetWD Removed"
author: "Jackie"
date: "December 2, 2017"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#knitr::opts_knit$get("root.dir")
```


```{r, echo=FALSE}

```


 
```{r tweets, echo=FALSE, message=FALSE, warning=FALSE}
# 
library(devtools)
library(twitteR)

api_key <- 	"KX9Sk6lCenrrn2yHCe2XKIVKi"
api_secret <- "TNbtVYjfzEfhWKKeKCG4MWbnzLapTyrCP5JhKx5pelVWvbwBO4"
access_token <- "927639225461366785-ct1z0xLv20fctGskDaVUwdBncX3udNw"
access_token_secret <- "l4C0SHwagaACa21SfejxSW79s1fg22Wm3vUamaJrh7Lkl"



setup_twitter_oauth(api_key, api_secret, access_token, access_token_secret)

# [1] "Using direct authentication"
# Use a local file ('.httr-oauth'), to cache OAuth access credentials between R sessions?
# 
# 1: Yes
# 2: No
# 
# Selection: 1
# Adding .httr-oauth to .gitignore


# getting tweets about chipotle from the beginng of the year and on
tweets <- searchTwitter("chipotle", n=7000, lang="en", since="2017-01-01")
# Transform tweets list into a data frame
tweets.df <- twListToDF(tweets)

# look at tweets about their queso; are people actually happy??:
#tweets.chipotle <- searchTwitter("chipotle", n=7000, lang="en", since="2017-09-12")
#tweets.chipotle <- twListToDF(tweets.chipotle)
#tweets.queso <- tweets.chipotle[grep("queso", tweets.chipotle$text),]

```




## Where People are Tweeting about Chipotle in the USA
```{r map, echo=FALSE, message=FALSE, warning=FALSE}
# trying to get locations of chipotle tweets
# yo <- searchTwitteR("chipotle", n = 11000, since = "2012-01-01")
# yodf <- twListToDF(yo)
# loc <- -1*is.na(yodf$longitude) + 1
# sum(loc)
# loc1  <- which(loc==1)
# locations <- data.frame(latitude = as.numeric(yodf$latitude[loc1]), longitude = as.numeric(yodf$longitude[loc1]))
# locations <- subset(locations, (latitude>=25 & latitude<=50) & (longitude>=-125 & longitude<=-65))

# trying to create map plotting tweets about chipotle in the usa 

library(ggplot2)
library(ggmap)
library(maps)
library(mapdata)

yodf.read <- read.csv(file="yodf.csv", header=TRUE)
loc.csv <- -1*is.na(yodf.read$longitude) + 1
loc1.csv  <- which(loc.csv==1)
locations.csv <- data.frame(latitude = as.numeric(yodf.read$latitude[loc1.csv]), longitude = as.numeric(yodf.read$longitude[loc1.csv]))
locations.csv <- subset(locations.csv, (latitude>=25 & latitude<=50) & (longitude>=-125 & longitude<=-65))
usa <- map_data("usa")
gg1 <- ggplot() + 
  geom_polygon(data = usa, aes(x=long, y = lat, group = group), fill = "#c9c9ff", color = "#ffb732") + 
  coord_fixed(1.3)
gg1 + geom_point(data = locations.csv, aes(x = longitude, y = latitude), color = "#35a79c", size =2)



# usa <- map_data("usa")
# gg1 <- ggplot() + 
#   geom_polygon(data = usa, aes(x=long, y = lat, group = group), fill = "#c9c9ff", color = "#ffb732") + 
#   coord_fixed(1.3)
# gg1 + geom_point(data = locations, aes(x = longitude, y = latitude), color = "#35a79c", size =2)



# map.queso <- searchTwitteR("chipotle", n = 11000, since = "2017-09-12")
# map.queso <- twListToDF(map.queso)
# map.queso <- map.queso[grep("queso", map.queso$text),]
# loc.1 <- -1*is.na(map.queso$longitude) + 1
# sum(loc.1)
# loc1.1  <- which(loc.1==1)
# locations.1 <- data.frame(latitude = as.numeric(map.queso$latitude[loc1.1]), longitude = as.numeric(map.queso$longitude[loc1.1]))
# locations.1 <- subset(locations.1, (latitude>=25 & latitude<=50) & (longitude>=-125 & longitude<=-65))
# gg1 + geom_point(data = locations.1, aes(x = longitude, y = latitude), color = "#35a79c", size =2)

```


Unfortunately, it can be quite difficult to gather a plethora of locations from tweets just because not many people choose to share their location of each tweet. I was able to gather about 40 locations from 11,000 tweets and plotted the longtitudes and latitudes. Although the locations are a small data set, there still appears to be some clustering going on that can still be useful information. In particular, the west and midwest regions of the country are extremely lacking in data points. There could be several reasons for this results. Perhaps Chipotle is less popular in these regions, or there may just be less Chipotle restaurant locations in these areas. I found a map online that displays Chipotle restaurant locations on a map of the USA (based on the data from "https://www.redliondata.com/chipotle-stores-map/". Interestingly enough, this map below bears a similar resemblance to the map above generated by the tweets, supporting the argument that people are tweeting about Chipotle less in the west and midwest regions of the United States because tehre are simply less Chipotle restaurants. The Chipotle marketing team should therefore focus on the areas in which there are a high number of Chipotles, which is mainly the southern part of the country and the northeast. However, it may also be of value for the marketing team to focus efforts on the extreme northwest part of the United States due to the fact that there are quite a few Chipotle restuarant locations there but it is lacking the Twitter traffic that could be helping their branding in that region. Perhaps the official Chipotle Twitter account could try to interact with users in that area more than it currently is.

![Chipotles in the USA](ChipotleUSALocations.png)



## Word Cloud

Below is a link to a Shiny app I have created that is an interactive word cloud that can alternate between representing words in tweets about Chipotle and, more specifically, tweets about Chipotle's queso. You can use the drop down to select the tweets you wish to have the word cloud express and press the "Change" button to watch the cloud change according to your choice. Then, you can use the sliders to modify the cloud based on the minimum frequency of the words and the maximum number of words. The bigger and bolder a word is within the word cloud, the more frequently it is used in the tweets. After looking at the word cloud at the link below, one can gather some information about how people tend ot tweet about Chipotle. 

https://jahorn.shinyapps.io/chipotle-wordcloud/





## Emoji Analysis

```{r emoji analysis, echo=FALSE, message=FALSE, warning=FALSE}



#set up Twitter Authentication
library(twitteR)
library(reshape)

###### GRAB TWEETS, PROCESS, AND WRITE TO DISK ######
# authenticate with twitter: get your credentials by creating an app at apps.twitter.com
# api_key <- 'KX9Sk6lCenrrn2yHCe2XKIVKi'
# api_secret <- 'TNbtVYjfzEfhWKKeKCG4MWbnzLapTyrCP5JhKx5pelVWvbwBO4'
# access_token <- '927639225461366785-ct1z0xLv20fctGskDaVUwdBncX3udNw'
# access_token_secret <- 'l4C0SHwagaACa21SfejxSW79s1fg22Wm3vUamaJrh7Lkl'
# setup_twitter_oauth(api_key, api_secret, access_token, access_token_secret)

# 2017.0202, #nobannowall
set.seed(20170202); ht <- 'chipotle';
tweets.raw <- searchTwitter(ht, n = 5000, lang = 'en');
df <- twListToDF(strip_retweets(tweets.raw, strip_manual = TRUE, strip_mt = TRUE)); df$hashtag <- ht; df$created <- as.POSIXlt(df$created); df$text <- iconv(df$text, 'latin1', 'ASCII', 'byte'); df$url <- paste0('https://twitter.com/', df$screenName, '/status/', df$id); df <- rename(df, c(retweetCount = 'retweets'));
df.a <- subset(df, select = c(text, created, url, latitude, longitude, retweets, hashtag));
#nrow(df.a); head(df.a);
#setwd("C:/Users/Jacqueline/Downloads/emojis-master/emojis-master/2017.0206 emoji data science tutorial");
write.csv(df.a, paste0('tweets.cleaned_', format(min(df.a$created), '%m%d'), '-', format(max(df.a$created), '%m%d'), '_', ht, '_', Sys.Date(), '_', format(Sys.time(), '%H-%M-%S'), '_n', nrow(df.a), '.csv'), row.names = FALSE);
tweets <- df; tweets$z <- 1; tweets$created <- as.POSIXlt(tweets$created); #nrow(tweets); min(tweets$created); max(tweets$created); median(tweets$created);




library(plyr)
library(ggplot2)
library(splitstackshape)
library(stringr)

####### READ IN SAVED TWITTER DATA
# change in fnames 'tutorial_tweets_raw' to
#setwd("C:/Users/Jacqueline/Downloads/emojis-master/emojis-master/2017.0206 emoji data science tutorial")
fnames <- c(
  'chipotle'
);
fnames <- paste0(fnames, '.csv'); df <- do.call(rbind.fill, lapply(fnames, read.csv));
df$username <- substr(substr(df$url, 21, nchar(as.character(df$url))), 1, nchar(substr(df$url, 21, nchar(as.character(df$url))))-26);
tweets.full <- df; tweets.full$X <- NULL; tweets.full$z <- 1;
#### sanity checking
tweets.full$created <- as.POSIXlt(tweets.full$created); #min(tweets.full$created); max(tweets.full$created); median(tweets.full$created); nrow(tweets.full); length(unique(tweets.full$username))
## dedupe dataset by url
tweets.dupes <- tweets.full[duplicated(tweets.full$url), ]; #nrow(tweets.full); nrow(tweets.dupes); # test <- subset(tweets.full, url %in% tweets.dupes$url); test <- test[with(test, order(url)), ];
tweets <- tweets.full[!duplicated(tweets.full$url), ]; tweets <- arrange(tweets, url); row.names(tweets) <- NULL; tweets$tweetid <- as.numeric(row.names(tweets)); #nrow(tweets);
tweets.final <- tweets;
## dedupe dataset by username
tweets.dupes <- tweets.full[duplicated(tweets.full$username), ]; #nrow(tweets.full); nrow(tweets.dupes); # test <- subset(tweets, url %in% tweets.dupes$url); test <- test[with(test, order(url)), ];
tweets <- tweets.full[!duplicated(tweets.full$username), ]; tweets <- arrange(tweets, url); row.names(tweets) <- NULL; tweets$tweetid <- as.numeric(row.names(tweets)); #nrow(tweets);

#### READ IN EMOJI DICTIONARIES
emdict.la <- read.csv('emoticon_conversion_noGraphic.csv', header = F); #Lauren Ancona; https://github.com/laurenancona/twimoji/tree/master/twitterEmojiProject
emdict.la <- emdict.la[-1, ]; row.names(emdict.la) <- NULL; names(emdict.la) <- c('unicode', 'bytes', 'name'); emdict.la$emojiid <- row.names(emdict.la);
emdict.jpb <- read.csv('emDict.csv', header = F) #Jessica Peterka-Bonetta; http://opiateforthemass.es/articles/emoticons-in-R/
emdict.jpb <- emdict.jpb[-1, ]; row.names(emdict.jpb) <- NULL; names(emdict.jpb) <- c('name', 'bytes', 'rencoding'); emdict.jpb$name <- tolower(emdict.jpb$name);
emdict.jpb$bytes <- NULL;
## merge dictionaries
emojis <- merge(emdict.la, emdict.jpb, by = 'name');  emojis$emojiid <- as.numeric(emojis$emojiid); emojis <- arrange(emojis, emojiid);

###### FIND TOP EMOJIS FOR A GIVEN SUBSET OF THE DATA
tweets <- tweets.final;
# tweets <- subset(tweets.final, hashtag %in% c('#womensmarch'));
## create full tweets by emojis matrix
df.s <- matrix(NA, nrow = nrow(tweets), ncol = ncol(emojis));
systemtime <- system.time(df.s <- sapply(emojis$rencoding, regexpr, tweets$text, ignore.case = T, useBytes = T));
rownames(df.s) <- 1:nrow(df.s); colnames(df.s) <- 1:ncol(df.s); df.t <- data.frame(df.s); df.t$tweetid <- tweets$tweetid;
# merge in hashtag data from original tweets dataset
df.a <- subset(tweets, select = c(tweetid, hashtag));
df.u <- merge(df.t, df.a, by = 'tweetid'); df.u$z <- 1; df.u <- arrange(df.u, tweetid);
tweets.emojis.matrix <- df.u;
## create emoji count dataset
df <- subset(tweets.emojis.matrix)[, c(2:843)]; count <- colSums(df > -1);
emojis.m <- cbind(count, emojis); emojis.m <- arrange(emojis.m, desc(count));
emojis.count <- subset(emojis.m, count > 1); emojis.count$dens <- round(1000 * (emojis.count$count / nrow(tweets)), 1); emojis.count$dens.sm <- (emojis.count$count + 1) / (nrow(tweets) + 1);
emojis.count$rank <- as.numeric(row.names(emojis.count));
emojis.count.p <- subset(emojis.count, select = c(name, dens, count, rank));
# print summary stats
#subset(emojis.count.p, rank <= 10);
num.tweets <- nrow(tweets); df.t <- rowSums(tweets.emojis.matrix[, c(2:843)] > -1); num.tweets.with.emojis <- length(df.t[df.t > 0]); num.emojis <- sum(emojis.count$count);
#min(tweets$created); max(tweets$created); median(tweets$created);
#num.tweets; num.tweets.with.emojis; round(100 * (num.tweets.with.emojis / num.tweets), 1); num.emojis; nrow(emojis.count);

##### MAKE BAR CHART OF TOP EMOJIS IN NEW DATASET
df.plot <- subset(emojis.count.p, rank <= 10); xlab <- 'Rank'; ylab <- 'Overall Frequency (per 5,000 Tweets)';
#opts_knit$set(root.dir = "C:/Users/Jacqueline/Downloads/emojis-master/ios_9_3_emoji_files")
#setwd("C:/Users/Jacqueline/Downloads/emojis-master/ios_9_3_emoji_files")
df.plot <- arrange(df.plot, name);
# error in imgs
imgs <- lapply(paste0(df.plot$name, '.png'), png::readPNG); g <- lapply(imgs, grid::rasterGrob);
k <- 0.20 * (10/nrow(df.plot)) * max(df.plot$dens); df.plot$xsize <- k; df.plot$ysize <- k; #df.plot$xsize <- k * (df.plot$dens / max(df.plot$dens)); df.plot$ysize <- k * (df.plot$dens / max(df.plot$dens));
df.plot <- arrange(df.plot, name);
# error in g1 with g because need imgs for g
##ff7954 peach
g1 <- ggplot(data = df.plot, aes(x = rank, y = dens)) +
  geom_bar(stat = 'identity', fill = '#f4a644') +
  xlab(xlab) + ylab(ylab) +
  mapply(function(x, y, i) {
    annotation_custom(g[[i]], xmin = x-0.5*df.plot$xsize[i], xmax = x+0.5*df.plot$xsize[i],
                      ymin = y-0.5*df.plot$ysize[i], ymax = y+0.5*df.plot$ysize[i])},
    df.plot$rank, df.plot$dens, seq_len(nrow(df.plot))) +
  scale_x_continuous(expand = c(0, 0), breaks = seq(1, nrow(df.plot), 1), labels = seq(1, nrow(df.plot), 1)) +
  scale_y_continuous(expand = c(0, 0), limits = c(0, 1.10 * max(df.plot$dens))) +
  theme(panel.grid.minor.y = element_blank(),
        axis.title.x = element_text(size = 10), axis.title.y = element_text(size = 14),
        axis.text.x  = element_text(size = 8, colour = 'black'), axis.text.y  = element_text(size = 8, colour = 'black')) + ggtitle("Most Common Emojis Tweeted with 'Chipotle'");
g1;
```

This chart above looks at the emojis being used in tweets about Chipotle and ranks the the top ten starting from most used to the left. Some of the top emojis can be logically interpreted, such as the heart eyes face, heart, praise hands, and smiling faces. However, the top two emojis can be a little confusing out of context. The top emoji tweeted along with "Chipotle" is the laugh crying face, followed by the crying face. These may seem sad or of mocking nature, but below are some example of tweets with these emojis to get a general idea of what the context of the tweet usually is. 


![Laugh crying face](Chipotle laugh emoji1.png)


![Crying face and laugh crying face](Chipotle laugh and cry emoji.png)


![Crying face](Chipotle cry emoji1.png)





These tweets pictured above are good examples of the context of the tweets containing these emojis. One can conclude from the chart and the tweets that most people tweeting about Chipotle and using emojis are tweeting positively about the restaurant chain.






## Sentiments Expressed in Tweets about Chipotle
 
```{r sentiments, echo=FALSE, message=FALSE, warning=FALSE}
library(tidytext)
library(tidyverse)
library(SnowballC)
library(stringr)
library(scales)

#write.csv(tweets.df, "tweets.df.csv")
#tweets.df.csv <- read.csv("tweets.df.csv")

tidy_tweets.df <- tweets.df %>% 
  unnest_tokens(word,text)

tidy_tweets.df <-  tidy_tweets.df %>% 
  anti_join(stop_words)


tweets.queso.1 <- searchTwitter("chipotle", n=7000, lang="en", since="2017-09-12")
tweets.queso.1 <- twListToDF(tweets.queso.1)
tweets.queso.1 <- tweets.queso.1[grep("queso", tweets.queso.1$text),]
#tweets.queso.csv <- read.csv(file="tweets.queso.1.csv", header=TRUE)

tidy_tweets.queso <- tweets.queso.1 %>% 
  unnest_tokens(word,text)

tidy_tweets.queso <-  tidy_tweets.queso %>% 
  anti_join(stop_words)


bing_word_counts <- tidy_tweets.df %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()

bing_word_counts %>%
  group_by(sentiment) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  scale_fill_manual(values=c("#ffb732", "#c9c9ff")) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y = "Contribution to Sentiment",
       x = NULL) +
  ggtitle("Word-Usage in Negative vs. Positive Tweets about Chipotle") +
  coord_flip()

```




Below is a table of a sample of 25 tweets that are about Chipotle and include the word "support", to show a glimpse of what these types of tweets look like.


```{r tweetgrid, echo=FALSE, message=FALSE, warning=FALSE}
# the word with highest contribution to the positive sentiment is "support"; so now we will look at what some of those tweets look like
tweets.df.support <- tweets.df[grep("support", tweets.df$text),]
library(gridExtra)

clean_tweet.support = gsub("&amp", "", tweets.df.support$text)
clean_tweet.support = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", clean_tweet.support)
clean_tweet.support = gsub("@\\w+", "", clean_tweet.support)
clean_tweet.support = gsub("[[:punct:]]", "", clean_tweet.support)
clean_tweet.support = gsub("[[:digit:]]", "", clean_tweet.support)
clean_tweet.support = gsub("http\\w+", "", clean_tweet.support)
clean_tweet.support = gsub("[ \t]{2,}", "", clean_tweet.support)
clean_tweet.support = gsub("^\\s+|\\s+$", "", clean_tweet.support)
clean_tweet.support <- str_replace_all(clean_tweet.support," "," ")
clean_tweet.support <- str_replace(clean_tweet.support,"RT @[a-z,A-Z]*: ","")
clean_tweet.support <- str_replace_all(clean_tweet.support,"#[a-z,A-Z]*","")
clean_tweet.support <- str_replace_all(clean_tweet.support,"@[a-z,A-Z]*","")  
clean_tweet.support <- gsub("@\\w+ *", "", clean_tweet.support)
clean_tweet.support <- gsub("#\\w+ *", "", clean_tweet.support)
clean_tweet.support <- gsub("\n", " ", clean_tweet.support)
clean_tweet.support <- gsub("[^a-zA-Z #]","",clean_tweet.support)    # "a-zA-Z #" are the things we need
clean_tweet.support <- gsub("https\\w+ *", "", clean_tweet.support)
clean_tweet.support <- tolower(clean_tweet.support)

tweets.support.ex <- clean_tweet.support[1:25]
grid.table(tweets.support.ex)
#tweets.support.ex <- as.data.frame(tweets.support.ex)
```


If you take a look at the group of tweets I pulled about Chipotle, it seems to be that a many of these tweets that include "support", which is a large proportion of positive tweets about Chipotle, are about different fundraisers that are being held at Chipotle and the tweets are mostly inviting people to come and "support" by coming to the participating Chipotle. This is much more reassuring about the reputation of Chipotle, being that the word clouds were slightly more negative. This chart may represent that there is still a lot of positivity surrounding the company, despite its various scandals and obstacles it has encountered in the recent years. Since these tweets are from the beginning of this current year on, we know we are getting tweets that have occured after most of the major negative publicity instances of Chipotle, showing that despite the issues Chipotle has had, many people still take on the opportunity to fundraise with the company and do good, which is beneficial to Chipotle's reputation as well.






```{r second sentiment chart, echo=FALSE, message=FALSE, warning=FALSE}
#If you take a look at the group of tweets I pulled about Chipotle, it seems to be that a grand majority of these tweets that include "support", which is a large proportion of positive tweets about Chipotle, are about different fundraisers that are being held at Chipotle and the tweets are mostly inviting people to come and "support" by coming to the participating Chipotle. This is much more reassuring about the reputation of Chipotle, being that the word clouds were slightly more negative. This chart may represent that there is still a lot of positivity surrounding the company, despite its various scandals and obstacles it has encountered in the recent years. Since these tweets are from the beginning of this current year on, we know we are getting tweets that have occured after most of the major negative publicity instances of Chipotle, showing that despite the issues Chipotle has had, many people still take on the opportunity to fundraise with the company and do good, which is beneficial to Chipotle's reputation as well.



bing_word_counts.1 <- tidy_tweets.queso %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()

bing_word_counts.1 %>%
  group_by(sentiment) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  scale_fill_manual(values=c("#ffb732", "#c9c9ff")) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y = "Contribution to Sentiment",
       x = NULL) +
  ggtitle("Word-Usage in Negative vs. Positive Tweets about Chipotle's Queso") +
  coord_flip()


```


Looking at the second set of charts regarding sentiment, more specifically about Chipotle's queso, it can be seen that there are sadly not many positive words being used in tweets regarding the new queso. On the other hand, there are much more negative words being used and at at a higher frequency. For example, "garbage" or "trash" tend to usually be at the top of the negative side, which does not mean good news for Chipotle. The queso was supposed to be a new marketing technique to help get customers back that may have made the decision to frequent the restaurant chain less often perhaps due to the e coli breakouts. This bid to get back its diners does not appear to be received well based on the tweet text analysis that has been performed. However, Chipotle should not lose hope because as shown in the first chart, there is still a fair amount of positivity surrounding the company but perhaps Chipotle should focus its efforts on coninuing to enhance its humanitarian image rather than promote its new queso.


